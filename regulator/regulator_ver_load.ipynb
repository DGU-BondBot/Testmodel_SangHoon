{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!file /content/KoBart_trained_transfer.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJGZ5KkxMujS",
        "outputId": "08cdd2e6-3e10-4dfc-fe68-46399676849a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBart_trained_transfer.zip: Zip archive data, at least v2.0 to extract, compression method=deflate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/KoBart_trained_transfer.zip -d /content/KoBart_trained_transfer"
      ],
      "metadata": {
        "id": "1GtfnfBFN-S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d27a6d-21c6-49c7-81ba-6eb66ae65f43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/KoBart_trained_transfer.zip\n",
            "  inflating: /content/KoBart_trained_transfer/model.safetensors  \n",
            "  inflating: /content/KoBart_trained_transfer/tokenizer_config.json  \n",
            "  inflating: /content/KoBart_trained_transfer/special_tokens_map.json  \n",
            "  inflating: /content/KoBart_trained_transfer/tokenizer.json  \n",
            "  inflating: /content/KoBart_trained_transfer/generation_config.json  \n",
            "  inflating: /content/KoBart_trained_transfer/config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
        "import pandas as pd\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "model_name = '/content/KoBart_trained_transfer'\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name).to('cuda')\n",
        "\n",
        "# 데이터셋 로드\n",
        "data_path = '/content/processed_smilestyle_dataset.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# 스타일 목록 추출\n",
        "styles = df['style'].unique()\n",
        "print(\"Available styles:\", styles)\n",
        "\n",
        "# 스타일에 맞춰 문장 생성 함수\n",
        "def change_style(input_text, style):\n",
        "    input_text = f\"<{style}> {input_text}\"\n",
        "    inputs = tokenizer(input_text, return_tensors='pt', max_length=128, truncation=True, padding='max_length').to('cuda')\n",
        "    outputs = model.generate(inputs['input_ids'], max_length=128, num_beams=5, early_stopping=True)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaDYMa9eIRRs",
        "outputId": "764deaf9-2986-45da-8648-c8e8bedcfbfe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available styles: ['gentle' 'sosim' 'informal' 'chat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트할 문장\n",
        "test_sentence = \"안녕 오늘따라 날씨도 좋은데 오늘 뭐 할 계획이야?\"\n",
        "\n",
        "# 각 스타일별로 문장 생성 및 출력\n",
        "for style in styles:\n",
        "    styled_sentence = change_style(test_sentence, style)\n",
        "    print(f\"Style: {style}\\nGenerated Text: {styled_sentence}\\n\")\n"
      ],
      "metadata": {
        "id": "r89IqfpoN4R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73534aeb-e765-438a-b77d-49ec777f5f92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Style: gentle\n",
            "Generated Text: 안녕하십니까. 오늘 날씨도 좋네요. 오늘 뭐하실 계획이십니까?\n",
            "\n",
            "Style: sosim\n",
            "Generated Text: 안녕 오늘 오늘따라 날씨도 좋은데 오늘 뭐할 계획이야 혹시..?\n",
            "\n",
            "Style: informal\n",
            "Generated Text: 안녕 오늘따라 날씨도 좋은데 오늘 뭐 할 계획이야?\n",
            "\n",
            "Style: chat\n",
            "Generated Text: ᄒᄋ 오늘 날씨도 좋긴한데 오늘 뭐 할 생각?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QirrWyvPLoVo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}